{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIuk-aUYQpVK",
        "outputId": "3a399857-7f6a-4f86-9f87-04d00d351512"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NEGATÄ°F Ã–RNEKLÄ° VERÄ° SETÄ° EÄžÄ°TÄ°M Ä°Ã‡Ä°N"
      ],
      "metadata": {
        "id": "3T5QabvgJ_H5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "# **ðŸ“Œ Sabitler**\n",
        "NUM_FRAMES = 512  # Modelin giriÅŸ boyutu\n",
        "FEATURE_DIM = 512  # CLIP Ã¶zellik boyutu\n",
        "NEG_SAMPLE_RATIO = 1  # Negatif Ã¶rnek oranÄ±\n",
        "\n",
        "# **ðŸ“Œ CSV DosyasÄ±nÄ± Okuma**\n",
        "csv_path = \"/content/drive/MyDrive/vid_sum_act/query_feature_training_all_sum.csv\"\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# **ðŸ“Œ Query Feature'larÄ±nÄ± Al (x_train_text)**\n",
        "x_train_text = np.array([\n",
        "    np.array(json.loads(text_feature)) for text_feature in df[\"text_feature\"]\n",
        "], dtype=np.float32)\n",
        "\n",
        "# **ðŸ“Œ Segmentleri Ground Truth (y_train) Olarak Al ve One-Hot Encode Yap**\n",
        "y_train = []\n",
        "for segment in df[\"segment\"]:\n",
        "    try:\n",
        "        # **Segment Listesini JSON'dan Parse Et**\n",
        "        segment_list = json.loads(segment) if isinstance(segment, str) else segment\n",
        "\n",
        "        # **One-Hot Encoded Maskeye Ã‡evir (512 Uzunlukta)**\n",
        "        mask = np.zeros(NUM_FRAMES, dtype=np.float32)\n",
        "        for idx in segment_list:\n",
        "            if 0 <= idx < NUM_FRAMES:\n",
        "                mask[idx] = 1\n",
        "\n",
        "        y_train.append(mask)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[WARNING] Segment iÅŸlenemedi: {segment}, Hata: {e}\")\n",
        "\n",
        "y_train = np.array(y_train, dtype=np.float32)  # (num_samples, 512)\n",
        "\n",
        "# **ðŸ“Œ CLIP Feature JSON Dosya YollarÄ±**\n",
        "clip_feature_paths = [\n",
        "    \"/content/drive/MyDrive/vid_sum_act/clip_features_1.json\",\n",
        "    \"/content/drive/MyDrive/vid_sum_act/clip_features_2.json\",\n",
        "    \"/content/drive/MyDrive/vid_sum_act/clip_features_3.json\",\n",
        "    \"/content/drive/MyDrive/vid_sum_act/clip_features_4.json\",\n",
        "    \"/content/drive/MyDrive/vid_sum_act/clip_features_5.json\",\n",
        "    \"/content/drive/MyDrive/vid_sum_act/clip_features_7.json\"\n",
        "]\n",
        "\n",
        "# **ðŸ“Œ Video Feature'larÄ±nÄ± Bellekte Tutmadan YÃ¼kleme**\n",
        "video_features = {}\n",
        "for path in clip_feature_paths:\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        video_features.update(json.load(f))\n",
        "\n",
        "# **ðŸ“Œ Video Feature'larÄ±nÄ± Al (GiriÅŸ: x_train_video)**\n",
        "x_train_video = []\n",
        "for video_id in df[\"video_id\"]:\n",
        "    if video_id in video_features:\n",
        "        x_train_video.append(np.array(video_features[video_id][\"frame_features\"], dtype=np.float32))\n",
        "    else:\n",
        "        continue\n",
        "# **ðŸ“Œ RAM KullanÄ±mÄ±nÄ± Optimize Etmek Ä°Ã§in Video Feature'larÄ± Bellekten Sil**\n",
        "del video_features\n",
        "\n",
        "# **ðŸ“Œ Negatif Ã–rnekleri OluÅŸturma**\n",
        "num_neg_samples = int(len(df) * NEG_SAMPLE_RATIO)  # %50 negatif Ã¶rnek\n",
        "\n",
        "# **Mevcut query ve video ID'leri**\n",
        "query_indices = list(range(len(x_train_text)))\n",
        "\n",
        "neg_x_train_text = []\n",
        "neg_x_train_video = []\n",
        "neg_y_train = []\n",
        "\n",
        "for _ in range(num_neg_samples):\n",
        "    # **FarklÄ± bir query ve yanlÄ±ÅŸ bir video seÃ§**\n",
        "    neg_query_idx = random.choice(query_indices)\n",
        "    neg_video_idx = random.choice(query_indices)\n",
        "\n",
        "    # **GerÃ§ek eÅŸleÅŸmelerden biri olmamasÄ±na dikkat et**\n",
        "    while df.iloc[neg_query_idx][\"video_id\"] == df.iloc[neg_video_idx][\"video_id\"]:\n",
        "        neg_video_idx = random.choice(query_indices)\n",
        "\n",
        "    # **Query ve yanlÄ±ÅŸ eÅŸleÅŸen gerÃ§ek video Ã¶zelliklerini ekle**\n",
        "    neg_x_train_text.append(x_train_text[neg_query_idx])  # **YanlÄ±ÅŸ query seÃ§iliyor!**\n",
        "    neg_x_train_video.append(x_train_video[neg_video_idx])  # **YanlÄ±ÅŸ video seÃ§iliyor!**\n",
        "\n",
        "    # **Negatif Ã–rnek: Ã‡Ä±kÄ±ÅŸ Sadece SÄ±fÄ±rlardan OluÅŸmalÄ±**\n",
        "    neg_y_train.append(np.zeros(NUM_FRAMES, dtype=np.float32))\n",
        "\n",
        "# **ðŸ“Œ Negatif ve Pozitif Ã–rnekleri BirleÅŸtirme**\n",
        "x_train_text = np.concatenate([x_train_text, np.array(neg_x_train_text, dtype=np.float32)], axis=0)\n",
        "x_train_video = np.concatenate([np.array(x_train_video, dtype=np.float32), np.array(neg_x_train_video, dtype=np.float32)], axis=0)\n",
        "y_train = np.concatenate([y_train, np.array(neg_y_train, dtype=np.float32)], axis=0)\n",
        "\n",
        "# **ðŸ“Œ Shuffle (KarÄ±ÅŸtÄ±rma)**\n",
        "num_samples = x_train_text.shape[0]\n",
        "shuffled_indices = np.random.permutation(num_samples)\n",
        "\n",
        "x_train_text = x_train_text[shuffled_indices]\n",
        "x_train_video = x_train_video[shuffled_indices]\n",
        "y_train = y_train[shuffled_indices]\n",
        "\n",
        "# **ðŸ“Œ Veri Seti Åžekillerini Kontrol Et**\n",
        "print(f\"[INFO] x_train_text shape: {x_train_text.shape}\")  # **(num_samples, 512)**\n",
        "print(f\"[INFO] x_train_video shape: {x_train_video.shape}\")  # **(num_samples, 512, 512)**\n",
        "print(f\"[INFO] y_train shape: {y_train.shape}\")  # **(num_samples, 512)**\")\n"
      ],
      "metadata": {
        "id": "4pIxbanQI_wg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NEGATÄ°F Ã–RNEKLÄ° VERÄ° SETÄ° DOÄžRULAMA VE TEST Ä°Ã‡Ä°N"
      ],
      "metadata": {
        "id": "eESfRFZvKFvF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "# **ðŸ“Œ Sabitler**\n",
        "NUM_FRAMES = 512  # Modelin giriÅŸ boyutu\n",
        "FEATURE_DIM = 512  # CLIP Ã¶zellik boyutu\n",
        "TEST_RATIO = 0.33  # **Test set oranÄ±**\n",
        "NEG_SAMPLE_RATIO = 1  # **Negatif Ã¶rnek oranÄ±**\n",
        "\n",
        "# **ðŸ“Œ Validation Ä°Ã§in KullanÄ±lacak CSV DosyasÄ±**\n",
        "val_csv_path = \"/content/drive/MyDrive/vid_sum_act/query_feature_val_all_sum.csv\"\n",
        "df_val = pd.read_csv(val_csv_path)\n",
        "\n",
        "# **ðŸ“Œ CLIP Feature JSON Dosya YollarÄ±**\n",
        "clip_feature_paths = [\n",
        "    \"/content/drive/MyDrive/vid_sum_act/clip_features_val_1.json\",\n",
        "    \"/content/drive/MyDrive/vid_sum_act/clip_features_val_2.json\"\n",
        "]\n",
        "\n",
        "# **ðŸ“Œ Video Feature'larÄ±nÄ± Bellekte Tutmadan YÃ¼kleme**\n",
        "video_features = {}\n",
        "for path in clip_feature_paths:\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        video_features.update(json.load(f))\n",
        "\n",
        "# **ðŸ“Œ Validation ve Test Setlerini AyÄ±rma**\n",
        "video_ids = df_val[\"video_id\"].unique()\n",
        "np.random.shuffle(video_ids)  # **Video ID'leri karÄ±ÅŸtÄ±r**\n",
        "test_size = int(len(video_ids) * TEST_RATIO)\n",
        "test_videos = set(video_ids[:test_size])  # **%33 Test**\n",
        "val_videos = set(video_ids[test_size:])  # **%67 Validation**\n",
        "\n",
        "df_test = df_val[df_val[\"video_id\"].isin(test_videos)].reset_index(drop=True)\n",
        "df_val = df_val[df_val[\"video_id\"].isin(val_videos)].reset_index(drop=True)\n",
        "\n",
        "def prepare_data(df):\n",
        "    \"\"\"Validation ve Test iÃ§in x_text, x_video, y verilerini hazÄ±rlar.\"\"\"\n",
        "\n",
        "    # **ðŸ“Œ Query Feature'larÄ±nÄ± CLIP formatÄ±na uygun ÅŸekilde yÃ¼kleme**\n",
        "    x_text = np.array([\n",
        "        np.array(json.loads(text_feature)) for text_feature in df[\"text_feature\"]\n",
        "    ], dtype=np.float32)\n",
        "\n",
        "    # **ðŸ“Œ Video Feature'larÄ±nÄ± yÃ¼kleme**\n",
        "    x_video = []\n",
        "    for video_id in df[\"video_id\"]:\n",
        "        if video_id in video_features:\n",
        "            x_video.append(np.array(video_features[video_id][\"frame_features\"], dtype=np.float32))\n",
        "        else:\n",
        "            continue\n",
        "    x_video = np.array(x_video, dtype=np.float32)  # (num_samples, 512, 512)\n",
        "\n",
        "    # **ðŸ“Œ Ground Truth'larÄ± HazÄ±rlama ve One-Hot Encode Yapma**\n",
        "    y = []\n",
        "    for segment in df[\"segment\"]:\n",
        "        try:\n",
        "            segment_list = json.loads(segment) if isinstance(segment, str) else segment\n",
        "\n",
        "            # **One-Hot Encoded Maskeye Ã‡evir (512 Uzunlukta)**\n",
        "            mask = np.zeros(NUM_FRAMES, dtype=np.float32)\n",
        "            for idx in segment_list:\n",
        "                if 0 <= idx < NUM_FRAMES:\n",
        "                    mask[idx] = 1\n",
        "\n",
        "            y.append(mask)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"[WARNING] Segment iÅŸlenemedi: {segment}, Hata: {e}\")\n",
        "\n",
        "    y = np.array(y, dtype=np.float32)  # (num_samples, 512)\n",
        "\n",
        "    # **ðŸ“Œ Negatif Ã–rnekler OluÅŸturma (Verinin %50'si Kadar)**\n",
        "    num_neg_samples = int(len(df) * NEG_SAMPLE_RATIO)  # %50 negatif Ã¶rnek\n",
        "\n",
        "    query_indices = list(range(len(x_text)))\n",
        "\n",
        "    neg_x_text = []\n",
        "    neg_x_video = []\n",
        "    neg_y = []\n",
        "\n",
        "    for _ in range(num_neg_samples):\n",
        "        # **FarklÄ± bir query ve yanlÄ±ÅŸ bir video seÃ§**\n",
        "        neg_query_idx = random.choice(query_indices)\n",
        "        neg_video_idx = random.choice(query_indices)\n",
        "\n",
        "        # **GerÃ§ek eÅŸleÅŸmelerden biri olmamasÄ±na dikkat et**\n",
        "        while df.iloc[neg_query_idx][\"video_id\"] == df.iloc[neg_video_idx][\"video_id\"]:\n",
        "            neg_video_idx = random.choice(query_indices)\n",
        "\n",
        "        # **YanlÄ±ÅŸ eÅŸleÅŸmiÅŸ gerÃ§ek video ve query seÃ§**\n",
        "        neg_x_text.append(x_text[neg_query_idx])  # **YanlÄ±ÅŸ query**\n",
        "        neg_x_video.append(x_video[neg_video_idx])  # **YanlÄ±ÅŸ video**\n",
        "\n",
        "        # **Negatif Ã–rnek: Ã‡Ä±kÄ±ÅŸ Sadece SÄ±fÄ±rlardan OluÅŸmalÄ±**\n",
        "        neg_y.append(np.zeros(NUM_FRAMES, dtype=np.float32))\n",
        "\n",
        "    # **ðŸ“Œ Negatif ve Pozitif Ã–rnekleri BirleÅŸtirme**\n",
        "    x_text = np.concatenate([x_text, np.array(neg_x_text, dtype=np.float32)], axis=0)\n",
        "    x_video = np.concatenate([x_video, np.array(neg_x_video, dtype=np.float32)], axis=0)\n",
        "    y = np.concatenate([y, np.array(neg_y, dtype=np.float32)], axis=0)\n",
        "\n",
        "    # **ðŸ“Œ Shuffle (KarÄ±ÅŸtÄ±rma)**\n",
        "    num_samples = x_text.shape[0]\n",
        "    shuffled_indices = np.random.permutation(num_samples)\n",
        "\n",
        "    x_text = x_text[shuffled_indices]\n",
        "    x_video = x_video[shuffled_indices]\n",
        "    y = y[shuffled_indices]\n",
        "\n",
        "    return x_text, x_video, y\n",
        "\n",
        "# **ðŸ“Œ Validation ve Test Verilerini HazÄ±rla (Negatif Ã–rneklerle)**\n",
        "x_val_text, x_val_video, y_val = prepare_data(df_val)\n",
        "x_test_text, x_test_video, y_test = prepare_data(df_test)\n",
        "\n",
        "# **ðŸ“Œ RAM KullanÄ±mÄ±nÄ± Optimize Etmek Ä°Ã§in Temizleme**\n",
        "del video_features\n",
        "\n",
        "# **ðŸ“Œ Veri Seti Åžekillerini Kontrol Et**\n",
        "print(f\"[INFO] x_val_text shape: {x_val_text.shape}\")  # **(num_samples, 512)**\n",
        "print(f\"[INFO] x_val_video shape: {x_val_video.shape}\")  # **(num_samples, 512, 512)**\n",
        "print(f\"[INFO] y_val shape: {y_val.shape}\")  # **(num_samples, 512)**\n",
        "\n",
        "print(f\"[INFO] x_test_text shape: {x_test_text.shape}\")  # **(num_samples, 512)**\n",
        "print(f\"[INFO] x_test_video shape: {x_test_video.shape}\")  # **(num_samples, 512, 512)**\n",
        "print(f\"[INFO] y_test shape: {y_test.shape}\")  # **(num_samples, 512)**\")\n"
      ],
      "metadata": {
        "id": "HuJ1mfmzJ1Fc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, MultiHeadAttention, BatchNormalization, Dropout, Add\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "# **ðŸ“Œ Transformer Encoder KatmanÄ±**\n",
        "class TransformerEncoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, dropout_rate=0.05):\n",
        "        super(TransformerEncoder, self).__init__()\n",
        "        self.attention = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.norm1 = BatchNormalization()  # **Batch Normalization Eklendi**\n",
        "        self.norm2 = BatchNormalization()\n",
        "        self.ffn = tf.keras.Sequential([\n",
        "            Dense(ff_dim, activation=\"relu\"),\n",
        "            Dense(embed_dim),\n",
        "        ])\n",
        "        self.dropout1 = Dropout(dropout_rate)\n",
        "        self.dropout2 = Dropout(dropout_rate)\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        attn_output = self.attention(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.norm1(inputs + attn_output, training=training)\n",
        "\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.norm2(out1 + ffn_output, training=training)\n",
        "\n",
        "# **ðŸ“Œ Cross-Attention KatmanÄ± (Video & Query EtkileÅŸimi)**\n",
        "class CrossAttentionLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, dropout_rate=0.05):\n",
        "        super(CrossAttentionLayer, self).__init__()\n",
        "        self.cross_attention = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.norm = BatchNormalization()  # **Batch Normalization Eklendi**\n",
        "        self.dropout = Dropout(dropout_rate)\n",
        "\n",
        "    def call(self, video_features, query_features, training=False):\n",
        "        query_expanded = tf.expand_dims(query_features, axis=1)  # (batch, 1, 512)\n",
        "        query_tiled = tf.tile(query_expanded, [1, 512, 1])  # (batch, 512, 512)\n",
        "\n",
        "        attn_output = self.cross_attention(query_tiled, video_features)\n",
        "        attn_output = self.dropout(attn_output, training=training)\n",
        "        return self.norm(video_features + attn_output, training=training)\n",
        "\n",
        "# **ðŸ“Œ Model Girdileri**\n",
        "video_input = Input(shape=(512, 512), name=\"video_features\")  # (512, 512) video CLIP Ã¶zellikleri\n",
        "\n",
        "# **ðŸ“Œ Video Ã–zelliklerini Ä°ÅŸle (Transformer Encoder)**\n",
        "video_encoded = TransformerEncoder(embed_dim=512, num_heads=8, ff_dim=1024)(video_input)\n",
        "\n",
        "# **ðŸ“Œ Query Ã–zellikleri: Modelin GiriÅŸinden AlÄ±nÄ±yor**\n",
        "query_input = Input(shape=(512,), name=\"query_embedding\")  # (512,) query CLIP Ã¶zelliÄŸi\n",
        "\n",
        "# **ðŸ“Œ Query Encoder**\n",
        "query_encoded = query_input\n",
        "\n",
        "# **ðŸ“Œ Video & Query Fusion (Cross-Attention)**\n",
        "cross_attention_output = CrossAttentionLayer(embed_dim=512, num_heads=8)(video_encoded, query_encoded)\n",
        "\n",
        "# **ðŸ“Œ Transformer Encoder ile Ã–zeti Ä°ÅŸle**\n",
        "decoder_output = TransformerEncoder(embed_dim=512, num_heads=8, ff_dim=1024)(cross_attention_output)\n",
        "\n",
        "# **ðŸ“Œ Ã‡Ä±ktÄ±yÄ± Frame SeÃ§imi Olarak Al (Binary Classification)**\n",
        "output = Dense(1, activation=\"sigmoid\")(decoder_output)  # (512, 1) â†’ frame selection\n",
        "\n",
        "# **ðŸ“Œ Modeli TanÄ±mla**\n",
        "model = Model(inputs=[video_input, query_input], outputs=output, name=\"QueryBasedVideoSummarization\")\n",
        "\n",
        "# **ðŸ“Œ Hybrid Loss (BCE + Dice Loss)**\n",
        "def dice_loss(y_true, y_pred):\n",
        "    smooth = 1.0\n",
        "    y_pred = K.clip(y_pred, 1e-7, 1.0 - 1e-7)  # **Normalize ettik**\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return 1 - (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "\n",
        "def hybrid_loss(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Binary Crossentropy ve Dice Loss kombinasyonu.\n",
        "    \"\"\"\n",
        "    bce = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
        "    dice = dice_loss(y_true, y_pred)\n",
        "    return 0.3 * bce + 0.7 * dice  # **Dice Loss'un aÄŸÄ±rlÄ±ÄŸÄ±nÄ± artÄ±rdÄ±k**\n",
        "\n",
        "# **ðŸ“Œ Modeli Derle**\n",
        "optimizer = Adam(learning_rate=2e-5)  # **Daha stabil Ã¶ÄŸrenme iÃ§in dÃ¼ÅŸÃ¼k Ã¶ÄŸrenme oranÄ±**\n",
        "model.compile(optimizer=optimizer, loss=hybrid_loss, metrics=[\"accuracy\"])\n",
        "\n",
        "# **ðŸ“Œ Modeli Kaydetmek Ä°Ã§in KlasÃ¶r Belirleme**\n",
        "save_dir = \"/content/drive/MyDrive/vid_sum_act/\"\n",
        "if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "\n",
        "# **ðŸ“Œ Checkpoint (Her Epoch SonrasÄ± En Ä°yi Modeli Kaydet)**\n",
        "checkpoint_path = os.path.join(save_dir, \"query_based_video_summarization.keras\")\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    checkpoint_path,\n",
        "    monitor=\"val_loss\",  # En iyi validation loss'a gÃ¶re kaydet\n",
        "    save_best_only=True,  # Sadece en iyi modeli kaydet\n",
        "    save_weights_only=False,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# **ðŸ“Œ Early Stopping (Overfitting'i Ã–nlemek Ä°Ã§in)**\n",
        "early_stopping_callback = EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    patience=10,  # EÄŸer 10 epoch boyunca iyileÅŸme olmazsa dur\n",
        "    restore_best_weights=True,  # En iyi aÄŸÄ±rlÄ±klarÄ± yÃ¼kle\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# **ðŸ“Œ EÄŸitim Parametreleri**\n",
        "batch_size = 16\n",
        "epochs = 50  # Maksimum 50 epoch\n",
        "\n",
        "# **ðŸ“Œ Modeli EÄŸit**\n",
        "history = model.fit(\n",
        "    [x_train_video, x_train_text],  # Modelin giriÅŸleri\n",
        "    y_train,  # Ground truth (One-hot encoded mask)\n",
        "    validation_data=([x_val_video, x_val_text], y_val),  # Validation set\n",
        "    epochs=epochs,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    callbacks=[early_stopping_callback, checkpoint_callback]\n",
        ")\n",
        "\n",
        "# **ðŸ“Œ En Ä°yi Modeli Kaydet**\n",
        "model.save(os.path.join(save_dir, \"final_query_based_video_summarization.keras\"))\n",
        "print(f\"ðŸ“Œ Model baÅŸarÄ±yla kaydedildi: {save_dir}\")\n"
      ],
      "metadata": {
        "id": "6oW51To-kfnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelin aÄŸÄ±rlÄ±klarÄ±nÄ± kaydetme\n",
        "\n",
        "model.save_weights('/content/drive/MyDrive/vid_sum_act/queryselfattn_weights.weights.h5')\n",
        "#model.load_weights(\"/content/drive/MyDrive/vid_sum_act/b-query_decodinp_based_video_summarization.weights.h5\")"
      ],
      "metadata": {
        "id": "1cUV11DAel-E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}